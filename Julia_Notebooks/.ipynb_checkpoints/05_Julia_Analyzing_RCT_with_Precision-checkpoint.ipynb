{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d3e509c",
   "metadata": {},
   "source": [
    "# Analyzing RCT with Precision by Adjusting for Baseline Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f97c4e8",
   "metadata": {},
   "source": [
    "# Jonathan Roth's DGP\n",
    "\n",
    "Here we set up a DGP with heterogenous effects. In this example, with is due to Jonathan Roth, we have\n",
    "$$\n",
    "E [Y(0) | Z] = - Z, \\quad E [Y(1) |Z] = Z, \\quad Z \\sim N(0,1).\n",
    "$$\n",
    "The CATE is\n",
    "$$\n",
    "E [Y(1) - Y(0) | Z ]= 2 Z.\n",
    "$$\n",
    "and the ATE is\n",
    "$$\n",
    "2 E Z = 0.\n",
    "$$\n",
    "\n",
    "We would like to estimate ATE as precisely as possible.\n",
    "\n",
    "An economic motivation for this example could be provided as follows: Let D be the treatment of going to college, and $Z$ academic skills.  Suppose that academic skills cause lower earnings Y(0) in jobs that don't require college degree, and cause higher earnings  Y(1) in jobs that require college degrees. This type of scenario is reflected in the DGP set-up above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c54642ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pkg; Pkg.add(\"Distributions\")\n",
    "# import Pkg; Pkg.add(\"Tables\")\n",
    "# import Pkg; Pkg.add(\"TableOperations\")\n",
    "# import Pkg; Pkg.add(\"StatsBase\")\n",
    "# import Pkg; Pkg.add(\"FreqTables\")\n",
    "# import Pkg; Pkg.add(\"Plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a5ebc024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages for splitting data\n",
    "using LinearAlgebra, GLM, DataFrames, Statistics, Random, Distributions, Tables, TableOperations, StatsBase, FreqTables, DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4da71180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.189"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set Seed\n",
    "# to make the results replicable (generating random numbers)\n",
    "Random.seed!(12345676)     # set MC seed\n",
    "\n",
    "n = 1000                # sample size\n",
    "Z = randn(n, 1)         # generate Z\n",
    "Y0 = -Z + randn(n, 1)   # conditional average baseline response is -Z\n",
    "Y1 = Z + randn(n, 1)    # conditional average treatment effect is +Z\n",
    "D = Int.(rand(Uniform(), n, 1) .< 0.2)   # treatment indicator; only 23% get treated\n",
    "length(D[D .== 1])*100/length(D[D .== 0])  # treatment indicator; only 23% get treated\n",
    "mean(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8351701e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×1 Matrix{Float64}:\n",
       "  1.726930592166616\n",
       "  2.6668920923293324\n",
       "  0.17260327143465098\n",
       "  0.22981794818549167\n",
       "  1.466898001424473\n",
       "  1.3529320088626253\n",
       "  0.1863114143889225\n",
       "  0.04369619043375853\n",
       " -0.5850402073066382\n",
       " -0.0643490070645289\n",
       " -1.10936088593052\n",
       " -0.8286904334211317\n",
       " -1.916406193712996\n",
       "  ⋮\n",
       " -1.1865268777224587\n",
       " -0.3632408555708126\n",
       "  0.7893783341581972\n",
       "  2.875748293624403\n",
       "  0.8344513543325733\n",
       "  1.0072571424293475\n",
       "  0.4003202863359305\n",
       " -0.6043502214480204\n",
       "  0.09863327796173031\n",
       " -2.45008621581788\n",
       " -1.8543324535087402\n",
       " -0.48790168982563364"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = (Y1.*D) + (Y0.*(ones(n,1)-D))    # observed Y\n",
    "D = D - fill(mean(D),n,1)            # demean D\n",
    "Z = Z - fill(mean(Z),n,1)            # demean Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95acfb6f",
   "metadata": {},
   "source": [
    "# Analyze the RCT data with Precision Adjustment\n",
    "\n",
    "Consider \n",
    "\n",
    "*  classical 2-sample approach, no adjustment (CL)\n",
    "*  classical linear regression adjustment (CRA)\n",
    "*  interactive regression adjusment (IRA)\n",
    "\n",
    "Carry out inference using robust inference, using the sandwich formulas (Eicker-Huber-White).  \n",
    "\n",
    "Observe that CRA delivers estimates that are less efficient than CL (pointed out by Freedman), whereas IRA delivers more efficient approach (pointed out by Lin). In order for CRA to be more efficient than CL, we need the CRA to be a correct model of the conditional expectation function of Y given D and X, which is not the case here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "06ce7e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>1,000 rows × 3 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>Z</th><th>D</th><th>Z_times_D</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>-0.189</td><td>1.72693</td><td>-0.32639</td></tr><tr><th>2</th><td>0.811</td><td>2.66689</td><td>2.16285</td></tr><tr><th>3</th><td>-0.189</td><td>0.172603</td><td>-0.032622</td></tr><tr><th>4</th><td>-0.189</td><td>0.229818</td><td>-0.0434356</td></tr><tr><th>5</th><td>-0.189</td><td>1.4669</td><td>-0.277244</td></tr><tr><th>6</th><td>-0.189</td><td>1.35293</td><td>-0.255704</td></tr><tr><th>7</th><td>-0.189</td><td>0.186311</td><td>-0.0352129</td></tr><tr><th>8</th><td>-0.189</td><td>0.0436962</td><td>-0.00825858</td></tr><tr><th>9</th><td>-0.189</td><td>-0.58504</td><td>0.110573</td></tr><tr><th>10</th><td>-0.189</td><td>-0.064349</td><td>0.012162</td></tr><tr><th>11</th><td>0.811</td><td>-1.10936</td><td>-0.899692</td></tr><tr><th>12</th><td>-0.189</td><td>-0.82869</td><td>0.156622</td></tr><tr><th>13</th><td>-0.189</td><td>-1.91641</td><td>0.362201</td></tr><tr><th>14</th><td>-0.189</td><td>1.4849</td><td>-0.280646</td></tr><tr><th>15</th><td>0.811</td><td>0.0416816</td><td>0.0338038</td></tr><tr><th>16</th><td>0.811</td><td>0.100034</td><td>0.0811278</td></tr><tr><th>17</th><td>-0.189</td><td>1.72016</td><td>-0.325111</td></tr><tr><th>18</th><td>-0.189</td><td>-0.6192</td><td>0.117029</td></tr><tr><th>19</th><td>-0.189</td><td>-1.34098</td><td>0.253445</td></tr><tr><th>20</th><td>-0.189</td><td>-0.168009</td><td>0.0317538</td></tr><tr><th>21</th><td>0.811</td><td>0.283359</td><td>0.229804</td></tr><tr><th>22</th><td>-0.189</td><td>1.22439</td><td>-0.231409</td></tr><tr><th>23</th><td>-0.189</td><td>0.00721673</td><td>-0.00136396</td></tr><tr><th>24</th><td>-0.189</td><td>0.589938</td><td>-0.111498</td></tr><tr><th>25</th><td>-0.189</td><td>-1.7345</td><td>0.32782</td></tr><tr><th>26</th><td>0.811</td><td>1.02695</td><td>0.832854</td></tr><tr><th>27</th><td>-0.189</td><td>0.978308</td><td>-0.1849</td></tr><tr><th>28</th><td>-0.189</td><td>-0.992186</td><td>0.187523</td></tr><tr><th>29</th><td>-0.189</td><td>-0.128773</td><td>0.0243381</td></tr><tr><th>30</th><td>-0.189</td><td>2.17567</td><td>-0.411201</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& Z & D & Z\\_times\\_D\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & -0.189 & 1.72693 & -0.32639 \\\\\n",
       "\t2 & 0.811 & 2.66689 & 2.16285 \\\\\n",
       "\t3 & -0.189 & 0.172603 & -0.032622 \\\\\n",
       "\t4 & -0.189 & 0.229818 & -0.0434356 \\\\\n",
       "\t5 & -0.189 & 1.4669 & -0.277244 \\\\\n",
       "\t6 & -0.189 & 1.35293 & -0.255704 \\\\\n",
       "\t7 & -0.189 & 0.186311 & -0.0352129 \\\\\n",
       "\t8 & -0.189 & 0.0436962 & -0.00825858 \\\\\n",
       "\t9 & -0.189 & -0.58504 & 0.110573 \\\\\n",
       "\t10 & -0.189 & -0.064349 & 0.012162 \\\\\n",
       "\t11 & 0.811 & -1.10936 & -0.899692 \\\\\n",
       "\t12 & -0.189 & -0.82869 & 0.156622 \\\\\n",
       "\t13 & -0.189 & -1.91641 & 0.362201 \\\\\n",
       "\t14 & -0.189 & 1.4849 & -0.280646 \\\\\n",
       "\t15 & 0.811 & 0.0416816 & 0.0338038 \\\\\n",
       "\t16 & 0.811 & 0.100034 & 0.0811278 \\\\\n",
       "\t17 & -0.189 & 1.72016 & -0.325111 \\\\\n",
       "\t18 & -0.189 & -0.6192 & 0.117029 \\\\\n",
       "\t19 & -0.189 & -1.34098 & 0.253445 \\\\\n",
       "\t20 & -0.189 & -0.168009 & 0.0317538 \\\\\n",
       "\t21 & 0.811 & 0.283359 & 0.229804 \\\\\n",
       "\t22 & -0.189 & 1.22439 & -0.231409 \\\\\n",
       "\t23 & -0.189 & 0.00721673 & -0.00136396 \\\\\n",
       "\t24 & -0.189 & 0.589938 & -0.111498 \\\\\n",
       "\t25 & -0.189 & -1.7345 & 0.32782 \\\\\n",
       "\t26 & 0.811 & 1.02695 & 0.832854 \\\\\n",
       "\t27 & -0.189 & 0.978308 & -0.1849 \\\\\n",
       "\t28 & -0.189 & -0.992186 & 0.187523 \\\\\n",
       "\t29 & -0.189 & -0.128773 & 0.0243381 \\\\\n",
       "\t30 & -0.189 & 2.17567 & -0.411201 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m1000×3 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m Z       \u001b[0m\u001b[1m D          \u001b[0m\u001b[1m Z_times_D   \u001b[0m\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64     \u001b[0m\n",
       "──────┼──────────────────────────────────\n",
       "    1 │  -0.189   1.72693    -0.32639\n",
       "    2 │   0.811   2.66689     2.16285\n",
       "    3 │  -0.189   0.172603   -0.032622\n",
       "    4 │  -0.189   0.229818   -0.0434356\n",
       "    5 │  -0.189   1.4669     -0.277244\n",
       "    6 │  -0.189   1.35293    -0.255704\n",
       "    7 │  -0.189   0.186311   -0.0352129\n",
       "    8 │  -0.189   0.0436962  -0.00825858\n",
       "    9 │  -0.189  -0.58504     0.110573\n",
       "   10 │  -0.189  -0.064349    0.012162\n",
       "   11 │   0.811  -1.10936    -0.899692\n",
       "  ⋮   │    ⋮         ⋮            ⋮\n",
       "  991 │  -0.189   0.789378   -0.149193\n",
       "  992 │  -0.189   2.87575    -0.543516\n",
       "  993 │  -0.189   0.834451   -0.157711\n",
       "  994 │  -0.189   1.00726    -0.190372\n",
       "  995 │  -0.189   0.40032    -0.0756605\n",
       "  996 │  -0.189  -0.60435     0.114222\n",
       "  997 │  -0.189   0.0986333  -0.0186417\n",
       "  998 │  -0.189  -2.45009     0.463066\n",
       "  999 │  -0.189  -1.85433     0.350469\n",
       " 1000 │  -0.189  -0.487902    0.0922134\n",
       "\u001b[36m                         979 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_times_D = Z.*D\n",
    "X = hcat(D, Z, Z_times_D)\n",
    "data = DataFrame(X, [:Z, :D, :Z_times_D])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a157eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages for OLS regression\n",
    "using GLM, Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "90cb462b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>1,000 rows × 4 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>Y</th><th>D</th><th>Z</th><th>Z_times_D</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>-1.57126</td><td>-0.189</td><td>1.72693</td><td>-0.32639</td></tr><tr><th>2</th><td>1.53851</td><td>0.811</td><td>2.66689</td><td>2.16285</td></tr><tr><th>3</th><td>-0.552237</td><td>-0.189</td><td>0.172603</td><td>-0.032622</td></tr><tr><th>4</th><td>0.241576</td><td>-0.189</td><td>0.229818</td><td>-0.0434356</td></tr><tr><th>5</th><td>-2.71474</td><td>-0.189</td><td>1.4669</td><td>-0.277244</td></tr><tr><th>6</th><td>-0.955155</td><td>-0.189</td><td>1.35293</td><td>-0.255704</td></tr><tr><th>7</th><td>-0.0891579</td><td>-0.189</td><td>0.186311</td><td>-0.0352129</td></tr><tr><th>8</th><td>-2.38482</td><td>-0.189</td><td>0.0436962</td><td>-0.00825858</td></tr><tr><th>9</th><td>2.28832</td><td>-0.189</td><td>-0.58504</td><td>0.110573</td></tr><tr><th>10</th><td>-0.101834</td><td>-0.189</td><td>-0.064349</td><td>0.012162</td></tr><tr><th>11</th><td>-1.31392</td><td>0.811</td><td>-1.10936</td><td>-0.899692</td></tr><tr><th>12</th><td>2.34802</td><td>-0.189</td><td>-0.82869</td><td>0.156622</td></tr><tr><th>13</th><td>3.90192</td><td>-0.189</td><td>-1.91641</td><td>0.362201</td></tr><tr><th>14</th><td>-3.48666</td><td>-0.189</td><td>1.4849</td><td>-0.280646</td></tr><tr><th>15</th><td>1.13804</td><td>0.811</td><td>0.0416816</td><td>0.0338038</td></tr><tr><th>16</th><td>0.290005</td><td>0.811</td><td>0.100034</td><td>0.0811278</td></tr><tr><th>17</th><td>-2.40993</td><td>-0.189</td><td>1.72016</td><td>-0.325111</td></tr><tr><th>18</th><td>-0.237082</td><td>-0.189</td><td>-0.6192</td><td>0.117029</td></tr><tr><th>19</th><td>2.8754</td><td>-0.189</td><td>-1.34098</td><td>0.253445</td></tr><tr><th>20</th><td>0.583754</td><td>-0.189</td><td>-0.168009</td><td>0.0317538</td></tr><tr><th>21</th><td>1.74147</td><td>0.811</td><td>0.283359</td><td>0.229804</td></tr><tr><th>22</th><td>-0.958462</td><td>-0.189</td><td>1.22439</td><td>-0.231409</td></tr><tr><th>23</th><td>0.422279</td><td>-0.189</td><td>0.00721673</td><td>-0.00136396</td></tr><tr><th>24</th><td>-0.913565</td><td>-0.189</td><td>0.589938</td><td>-0.111498</td></tr><tr><th>25</th><td>1.38136</td><td>-0.189</td><td>-1.7345</td><td>0.32782</td></tr><tr><th>26</th><td>1.1622</td><td>0.811</td><td>1.02695</td><td>0.832854</td></tr><tr><th>27</th><td>-1.97462</td><td>-0.189</td><td>0.978308</td><td>-0.1849</td></tr><tr><th>28</th><td>1.6689</td><td>-0.189</td><td>-0.992186</td><td>0.187523</td></tr><tr><th>29</th><td>0.730834</td><td>-0.189</td><td>-0.128773</td><td>0.0243381</td></tr><tr><th>30</th><td>-2.47703</td><td>-0.189</td><td>2.17567</td><td>-0.411201</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& Y & D & Z & Z\\_times\\_D\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & -1.57126 & -0.189 & 1.72693 & -0.32639 \\\\\n",
       "\t2 & 1.53851 & 0.811 & 2.66689 & 2.16285 \\\\\n",
       "\t3 & -0.552237 & -0.189 & 0.172603 & -0.032622 \\\\\n",
       "\t4 & 0.241576 & -0.189 & 0.229818 & -0.0434356 \\\\\n",
       "\t5 & -2.71474 & -0.189 & 1.4669 & -0.277244 \\\\\n",
       "\t6 & -0.955155 & -0.189 & 1.35293 & -0.255704 \\\\\n",
       "\t7 & -0.0891579 & -0.189 & 0.186311 & -0.0352129 \\\\\n",
       "\t8 & -2.38482 & -0.189 & 0.0436962 & -0.00825858 \\\\\n",
       "\t9 & 2.28832 & -0.189 & -0.58504 & 0.110573 \\\\\n",
       "\t10 & -0.101834 & -0.189 & -0.064349 & 0.012162 \\\\\n",
       "\t11 & -1.31392 & 0.811 & -1.10936 & -0.899692 \\\\\n",
       "\t12 & 2.34802 & -0.189 & -0.82869 & 0.156622 \\\\\n",
       "\t13 & 3.90192 & -0.189 & -1.91641 & 0.362201 \\\\\n",
       "\t14 & -3.48666 & -0.189 & 1.4849 & -0.280646 \\\\\n",
       "\t15 & 1.13804 & 0.811 & 0.0416816 & 0.0338038 \\\\\n",
       "\t16 & 0.290005 & 0.811 & 0.100034 & 0.0811278 \\\\\n",
       "\t17 & -2.40993 & -0.189 & 1.72016 & -0.325111 \\\\\n",
       "\t18 & -0.237082 & -0.189 & -0.6192 & 0.117029 \\\\\n",
       "\t19 & 2.8754 & -0.189 & -1.34098 & 0.253445 \\\\\n",
       "\t20 & 0.583754 & -0.189 & -0.168009 & 0.0317538 \\\\\n",
       "\t21 & 1.74147 & 0.811 & 0.283359 & 0.229804 \\\\\n",
       "\t22 & -0.958462 & -0.189 & 1.22439 & -0.231409 \\\\\n",
       "\t23 & 0.422279 & -0.189 & 0.00721673 & -0.00136396 \\\\\n",
       "\t24 & -0.913565 & -0.189 & 0.589938 & -0.111498 \\\\\n",
       "\t25 & 1.38136 & -0.189 & -1.7345 & 0.32782 \\\\\n",
       "\t26 & 1.1622 & 0.811 & 1.02695 & 0.832854 \\\\\n",
       "\t27 & -1.97462 & -0.189 & 0.978308 & -0.1849 \\\\\n",
       "\t28 & 1.6689 & -0.189 & -0.992186 & 0.187523 \\\\\n",
       "\t29 & 0.730834 & -0.189 & -0.128773 & 0.0243381 \\\\\n",
       "\t30 & -2.47703 & -0.189 & 2.17567 & -0.411201 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m1000×4 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m Y          \u001b[0m\u001b[1m D       \u001b[0m\u001b[1m Z          \u001b[0m\u001b[1m Z_times_D   \u001b[0m\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64    \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64     \u001b[0m\n",
       "──────┼──────────────────────────────────────────────\n",
       "    1 │ -1.57126     -0.189   1.72693    -0.32639\n",
       "    2 │  1.53851      0.811   2.66689     2.16285\n",
       "    3 │ -0.552237    -0.189   0.172603   -0.032622\n",
       "    4 │  0.241576    -0.189   0.229818   -0.0434356\n",
       "    5 │ -2.71474     -0.189   1.4669     -0.277244\n",
       "    6 │ -0.955155    -0.189   1.35293    -0.255704\n",
       "    7 │ -0.0891579   -0.189   0.186311   -0.0352129\n",
       "    8 │ -2.38482     -0.189   0.0436962  -0.00825858\n",
       "    9 │  2.28832     -0.189  -0.58504     0.110573\n",
       "   10 │ -0.101834    -0.189  -0.064349    0.012162\n",
       "   11 │ -1.31392      0.811  -1.10936    -0.899692\n",
       "  ⋮   │     ⋮          ⋮         ⋮            ⋮\n",
       "  991 │ -2.83529     -0.189   0.789378   -0.149193\n",
       "  992 │ -3.65031     -0.189   2.87575    -0.543516\n",
       "  993 │ -0.0480137   -0.189   0.834451   -0.157711\n",
       "  994 │ -0.115628    -0.189   1.00726    -0.190372\n",
       "  995 │ -0.774222    -0.189   0.40032    -0.0756605\n",
       "  996 │  1.54838     -0.189  -0.60435     0.114222\n",
       "  997 │  0.458729    -0.189   0.0986333  -0.0186417\n",
       "  998 │  2.20163     -0.189  -2.45009     0.463066\n",
       "  999 │  3.01825     -0.189  -1.85433     0.350469\n",
       " 1000 │  1.32553     -0.189  -0.487902    0.0922134\n",
       "\u001b[36m                                     979 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aux = [Y D Z Z_times_D]\n",
    "data_aux = DataFrame(data_aux, [:Y, :D, :Z, :Z_times_D])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f68997d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FormulaTerm\n",
       "Response:\n",
       "  Y(unknown)\n",
       "Predictors:\n",
       "  D(unknown)\n",
       "  Z(unknown)\n",
       "  Z_times_D(unknown)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_1 = @formula(Y ~ D)\n",
    "fm_2 = @formula(Y ~ D + Z)\n",
    "fm_3 = @formula(Y ~ D + Z + Z_times_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "70f6adda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CL_model = StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
      "\n",
      "Y ~ 1 + D\n",
      "\n",
      "Coefficients:\n",
      "─────────────────────────────────────────────────────────────────────────\n",
      "                 Coef.  Std. Error     t  Pr(>|t|)   Lower 95%  Upper 95%\n",
      "─────────────────────────────────────────────────────────────────────────\n",
      "(Intercept)  0.0450644   0.0555981  0.81    0.4178  -0.0640381   0.154167\n",
      "D            0.0593067   0.14201    0.42    0.6763  -0.219366    0.337979\n",
      "─────────────────────────────────────────────────────────────────────────\n",
      "CRA_model = StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
      "\n",
      "Y ~ 1 + D + Z\n",
      "\n",
      "Coefficients:\n",
      "────────────────────────────────────────────────────────────────────────────\n",
      "                  Coef.  Std. Error       t  Pr(>|t|)   Lower 95%  Upper 95%\n",
      "────────────────────────────────────────────────────────────────────────────\n",
      "(Intercept)   0.0450644   0.0438522    1.03    0.3044  -0.0409888   0.131118\n",
      "D             0.118474    0.112034     1.06    0.2905  -0.101375    0.338324\n",
      "Z            -1.04527     0.0424182  -24.64    <1e-99  -1.12851    -0.96203\n",
      "────────────────────────────────────────────────────────────────────────────\n",
      "IRA_model = StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
      "\n",
      "Y ~ 1 + D + Z + Z_times_D\n",
      "\n",
      "Coefficients:\n",
      "───────────────────────────────────────────────────────────────────────────\n",
      "                  Coef.  Std. Error       t  Pr(>|t|)  Lower 95%  Upper 95%\n",
      "───────────────────────────────────────────────────────────────────────────\n",
      "(Intercept)   0.0278515   0.0362395    0.77    0.4423  -0.043263   0.098966\n",
      "D             0.0471567   0.0926216    0.51    0.6108  -0.134599   0.228913\n",
      "Z            -1.01934     0.0350665  -29.07    <1e-99  -1.08815   -0.950523\n",
      "Z_times_D     1.98389     0.0920421   21.55    <1e-84   1.80327    2.16451\n",
      "───────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "Y ~ 1 + D + Z + Z_times_D\n",
       "\n",
       "Coefficients:\n",
       "───────────────────────────────────────────────────────────────────────────\n",
       "                  Coef.  Std. Error       t  Pr(>|t|)  Lower 95%  Upper 95%\n",
       "───────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)   0.0278515   0.0362395    0.77    0.4423  -0.043263   0.098966\n",
       "D             0.0471567   0.0926216    0.51    0.6108  -0.134599   0.228913\n",
       "Z            -1.01934     0.0350665  -29.07    <1e-99  -1.08815   -0.950523\n",
       "Z_times_D     1.98389     0.0920421   21.55    <1e-84   1.80327    2.16451\n",
       "───────────────────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CL_model = lm(fm_1, data_aux)\n",
    "CRA_model = lm(fm_2, data_aux)  #classical\n",
    "IRA_model = lm(fm_3, data_aux)  #interactive approach\n",
    "# Standard deviations for estimators\n",
    "CL = sqrt(sum((Y - predict(CL_model)).*(Y - predict(CL_model)))./length(Y))\n",
    "CRA = sqrt(sum((Y - predict(CRA_model)).*(Y - predict(CRA_model)))./length(Y))\n",
    "IRA = sqrt(sum((Y - predict(IRA_model)).*(Y - predict(IRA_model)))./length(Y))\n",
    "@show CL\n",
    "@show CRA\n",
    "@show IRA\n",
    "\n",
    "# Check t values of regressors \n",
    "@show coeftable(CL_model).cols[4]\n",
    "@show coeftable(CRA_model).cols[4]\n",
    "@show coeftable(IRA_model).cols[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f4bc071d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F-test: 3 models fitted on 1000 observations\n",
       "───────────────────────────────────────────────────────────────────────\n",
       "     DOF  ΔDOF        SSR        ΔSSR      R²     ΔR²        F*   p(>F)\n",
       "───────────────────────────────────────────────────────────────────────\n",
       "[1]    3        3084.9642              0.0002                          \n",
       "[2]    4     1  1917.2505  -1167.7137  0.3786  0.3785  607.2293  <1e-99\n",
       "[3]    5     1  1307.4120   -609.8385  0.5763  0.1976  464.5813  <1e-84\n",
       "───────────────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing models\n",
    "ftest(CL_model.model, CRA_model.model, IRA_model.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060d3219-0990-4e5b-b4e2-d4d3517f27a8",
   "metadata": {},
   "source": [
    "# Using classical standard errors (non-robust) is misleading here.\n",
    "\n",
    "We don't teach non-robust standard errors in econometrics courses, but the default statistical inference for lm() procedure in R, summary.lm(), still uses 100-year old concepts, perhaps in part due to historical legacy.  \n",
    "\n",
    "Here the non-robust standard errors suggest that there is not much difference between the different approaches, contrary to the conclusions reached using the robust standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4925c968-a302-4ec8-8e39-209948e6ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "@show CL_model\n",
    "@show CRA_model\n",
    "@show IRA_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2601920",
   "metadata": {},
   "source": [
    "# Verify Asymptotic Approximations Hold in Finite-Sample Simulation Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "170849bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviations for estimators\n",
      "CL model: 1.4545726198637772\n",
      "CRA model: 1.3097621564719322\n",
      "IRA model: 1.0235301183486727\n"
     ]
    }
   ],
   "source": [
    "Random.seed!(12345676)     # set MC seed\n",
    "n = 1000\n",
    "B = 1000\n",
    "\n",
    "# format of data = float32\n",
    "CLs = fill(0., B)\n",
    "CRAs = fill(0., B)\n",
    "IRAs = fill(0., B)\n",
    "\n",
    "\n",
    "# formulas for regressions\n",
    "fm_1 = @formula(Y ~ D)\n",
    "fm_2 = @formula(Y ~ D + Z)\n",
    "fm_3 = @formula(Y ~ D + Z + Z_times_D)\n",
    "\n",
    "# models\n",
    "CL_model = lm(fm_1, data_aux)\n",
    "CRA_model = lm(fm_2, data_aux)  #classical\n",
    "IRA_model = lm(fm_3, data_aux)  #interactive approach\n",
    "\n",
    "\n",
    "# simulation\n",
    "for i in 1:B\n",
    "    Z = randn(n, 1)         # generate Z\n",
    "    Y0 = -Z + randn(n, 1)   # conditional average baseline response is -Z\n",
    "    Y1 = Z + randn(n, 1)    # conditional average treatment effect is +Z\n",
    "    D = Int.(rand(Uniform(), n, 1) .< 0.2)   # treatment indicator; only 23% get treated\n",
    "\n",
    "    Y = (Y1.*D) + (Y0.*(ones(n,1)-D))    # observed Y\n",
    "\n",
    "    D = D - fill(mean(D),n,1)            # demean D\n",
    "    Z = Z - fill(mean(Z),n,1)            # demean Z\n",
    "\n",
    "    Z_times_D = Z.*D\n",
    "    X = hcat(D, Z, Z_times_D)\n",
    "    data_aux = [Y D Z Z_times_D]\n",
    "    data_aux = DataFrame(data_aux, [:Y, :D, :Z, :Z_times_D])\n",
    "    \n",
    "    CLs[i,] = predict(CL_model)[i]\n",
    "    CRAs[i,] = predict(CRA_model)[i]\n",
    "    IRAs[i,] = predict(IRA_model)[i]\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "# check  standard deviations\n",
    "println(\"Standard deviations for estimators\")  \n",
    "println(\"CL model: \" , sqrt(sum((Y - predict(CL_model)).*(Y - predict(CL_model)))./length(Y)))\n",
    "println(\"CRA model: \" , sqrt(sum((Y - predict(CL_model)).*(Y - predict(CRA_model)))./length(Y)))\n",
    "println(\"IRA model: \" , sqrt(sum((Y - predict(CL_model)).*(Y - predict(IRA_model)))./length(Y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
