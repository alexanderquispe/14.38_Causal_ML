{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an example for teaching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Effect of Gun Ownership on Gun-Homicide Rates - proceeding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we estimate the effect of gun ownership on the homicide rate by a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `C:\\Users\\PC\\.julia\\registries\\General`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\PC\\.julia\\environments\\v1.6\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\PC\\.julia\\environments\\v1.6\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\PC\\.julia\\environments\\v1.6\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\PC\\.julia\\environments\\v1.6\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\PC\\.julia\\environments\\v1.6\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\PC\\.julia\\environments\\v1.6\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\PC\\.julia\\environments\\v1.6\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\PC\\.julia\\environments\\v1.6\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\PC\\.julia\\environments\\v1.6\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\PC\\.julia\\environments\\v1.6\\Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"CSV\"), using CSV\n",
    "Pkg.add(\"DataFrames\"), using DataFrames\n",
    "Pkg.add(\"StatsModels\"), using StatsModels\n",
    "Pkg.add(\"GLM\"), using GLM\n",
    "Pkg.add(\"Random\"), using Random\n",
    "using Statistics, Plots, FixedEffectModels, MLDataUtils, MLBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to load and preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 3900\n",
      "Number of columns: 415\n"
     ]
    }
   ],
   "source": [
    "data = CSV.File(\"../data/gun_clean.csv\") |> DataFrame;\n",
    "println(\"Number of rows: \",size(data,1))\n",
    "println(\"Number of columns: \",size(data,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Create Variables ###############################\n",
    "\n",
    "# Dummy Variables for Year and County Fixed Effects\n",
    "fixed = filter(x->contains(x, \"X_Jfips\"), names(data));\n",
    "year = filter(x->contains(x, \"X_Tyear\"), names(data));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = []\n",
    "census_var = [\"AGE\", \"BN\", \"BP\", \"BZ\", \"ED\", \"EL\", \"HI\", \"HS\", \"INC\", \"LF\", \"LN\", \"PI\", \"PO\", \"PP\", \"PV\", \"SPR\", \"VS\"]\n",
    "\n",
    "for i in 1:size(census_var,1) \n",
    "    append!(census, filter(x->contains(x, census_var[i]), names(data)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Variables ##################################\n",
    "\n",
    "# Treatment Variable\n",
    "d = [\"logfssl\"];\n",
    "\n",
    "# Outcome Variable\n",
    "y = [\"logghomr\"];\n",
    "\n",
    "# Other Control Variables\n",
    "X1 = [\"logrobr\", \"logburg\", \"burg_missing\", \"robrate_missing\"];\n",
    "X2 = [\"newblack\", \"newfhh\", \"newmove\", \"newdens\", \"newmal\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################  Partial out Fixed Effects ########################\n",
    "\n",
    "# Variables to be Partialled-out\n",
    "variable = [y, d,X1, X2, census]\n",
    "varlis = []\n",
    "\n",
    "# Partial out Variables in varlist from year and county fixed effect\n",
    "for i in variable\n",
    "    append!(varlis,i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the following lines takes aprox. 10 minutes (depends on your CPU)\n",
    "\n",
    "example = DataFrame(CountyCode = data[:,\"CountyCode\"]);\n",
    "rdata = DataFrame(CountyCode = data[:,\"CountyCode\"]);\n",
    "\n",
    "for i in 1:size(varlis,1)\n",
    "    rdata[!,varlis[i]]= residuals(lm(term(Symbol(varlis[i])) ~ sum(term.(Symbol.(year))) + sum(term.(Symbol.(fixed))), data))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DML for neural nets\n",
    "\n",
    "The following algorithm comsumes $Y$,$D$ and $Z$, and learns the residuals $\\tilde{Y}$ and $\\tilde{D}$ via a neural network, where the residuals are obtained by cross-validation (cross-fitting). Then, it prints the estimated coefficient β and the clustered standard error from the final OLS regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: crossentropy, @epochs\n",
    "using Flux.Data: DataLoader\n",
    "using Flux: throttle\n",
    "using Flux: onehotbatch, onecold, @epochs\n",
    "using StatsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>logrobr</th><th>logburg</th><th>burg_missing</th><th>robrate_missing</th><th>newblack</th><th>newfhh</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>3,900 rows × 195 columns (omitted printing of 189 columns)</p><tr><th>1</th><td>0.150893</td><td>-0.124395</td><td>0.0104613</td><td>-0.021229</td><td>0.0309471</td><td>-0.0204832</td></tr><tr><th>2</th><td>0.0401683</td><td>-0.134781</td><td>0.0104613</td><td>-0.0194181</td><td>0.0309471</td><td>-0.0204832</td></tr><tr><th>3</th><td>-0.017679</td><td>-0.167909</td><td>0.0104613</td><td>-0.0220374</td><td>0.0309471</td><td>-0.0204832</td></tr><tr><th>4</th><td>-0.00963344</td><td>-0.22925</td><td>0.0104613</td><td>-0.0194181</td><td>0.0309471</td><td>-0.0204832</td></tr><tr><th>5</th><td>-0.0267151</td><td>-0.176635</td><td>0.00324793</td><td>-0.0208037</td><td>0.0309471</td><td>-0.0204832</td></tr><tr><th>6</th><td>-0.151487</td><td>-0.189069</td><td>0.0104613</td><td>0.016953</td><td>0.0309471</td><td>-0.0204832</td></tr><tr><th>7</th><td>-0.166729</td><td>-0.117739</td><td>0.0104613</td><td>0.0245505</td><td>0.0309471</td><td>-0.0204832</td></tr><tr><th>8</th><td>-0.0996453</td><td>-0.0833094</td><td>0.00448964</td><td>0.021457</td><td>0.0309471</td><td>-0.0204832</td></tr><tr><th>9</th><td>0.151557</td><td>0.319282</td><td>-0.0448348</td><td>-0.0366629</td><td>0.0309471</td><td>-0.0204832</td></tr><tr><th>10</th><td>0.0476034</td><td>-0.0144728</td><td>-0.00233214</td><td>0.00765442</td><td>0.0309471</td><td>-0.0204832</td></tr><tr><th>11</th><td>0.00814297</td><td>-0.0349694</td><td>0.0104613</td><td>0.0101673</td><td>-0.0309471</td><td>0.0204832</td></tr><tr><th>12</th><td>-0.0811847</td><td>0.0441466</td><td>0.00848568</td><td>0.0169169</td><td>-0.0309471</td><td>0.0204832</td></tr><tr><th>13</th><td>-0.153504</td><td>0.393015</td><td>-0.0484441</td><td>0.0230577</td><td>-0.0309471</td><td>0.0204832</td></tr><tr><th>14</th><td>-0.148069</td><td>-0.0146316</td><td>0.00886135</td><td>0.0161103</td><td>-0.0309471</td><td>0.0204832</td></tr><tr><th>15</th><td>0.0247091</td><td>0.0531618</td><td>0.00677168</td><td>0.0155368</td><td>-0.0309471</td><td>0.0204832</td></tr><tr><th>16</th><td>0.235093</td><td>0.178299</td><td>-0.00374318</td><td>0.000594213</td><td>-0.0309471</td><td>0.0204832</td></tr><tr><th>17</th><td>0.294984</td><td>0.146047</td><td>-0.00460173</td><td>-0.0205562</td><td>-0.0309471</td><td>0.0204832</td></tr><tr><th>18</th><td>0.0237644</td><td>0.0162414</td><td>0.00588019</td><td>0.00584345</td><td>-0.0309471</td><td>0.0204832</td></tr><tr><th>19</th><td>-0.116843</td><td>-0.0173146</td><td>0.00543154</td><td>0.0053948</td><td>-0.0309471</td><td>0.0204832</td></tr><tr><th>20</th><td>-0.00542654</td><td>0.154285</td><td>-0.0124411</td><td>-0.00411101</td><td>-0.0309471</td><td>0.0204832</td></tr><tr><th>21</th><td>0.106903</td><td>-0.117615</td><td>0.00797198</td><td>-0.0161775</td><td>0.0425486</td><td>-0.0222253</td></tr><tr><th>22</th><td>0.0906478</td><td>-0.0953381</td><td>0.00797198</td><td>-0.0147974</td><td>0.0425486</td><td>-0.0222253</td></tr><tr><th>23</th><td>0.0844482</td><td>-0.115481</td><td>0.00797198</td><td>-0.0167935</td><td>0.0425486</td><td>-0.0222253</td></tr><tr><th>24</th><td>0.0297359</td><td>-0.187202</td><td>0.00797198</td><td>-0.0147974</td><td>0.0425486</td><td>-0.0222253</td></tr><tr><th>25</th><td>-0.0270093</td><td>-0.187794</td><td>0.00247507</td><td>-0.0158534</td><td>0.0425486</td><td>-0.0222253</td></tr><tr><th>26</th><td>-0.220044</td><td>-0.148477</td><td>0.00797198</td><td>0.0129189</td><td>0.0425486</td><td>-0.0222253</td></tr><tr><th>27</th><td>-0.2442</td><td>-0.0289042</td><td>0.00797198</td><td>0.0187086</td><td>0.0425486</td><td>-0.0222253</td></tr><tr><th>28</th><td>-0.217045</td><td>0.127496</td><td>0.00342131</td><td>0.0163512</td><td>0.0425486</td><td>-0.0222253</td></tr><tr><th>29</th><td>0.10424</td><td>0.393619</td><td>-0.0341662</td><td>-0.0279388</td><td>0.0425486</td><td>-0.0222253</td></tr><tr><th>30</th><td>-0.172381</td><td>-0.00919521</td><td>-0.0017772</td><td>0.00583301</td><td>0.0425486</td><td>-0.0222253</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& logrobr & logburg & burg\\_missing & robrate\\_missing & newblack & newfhh & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 0.150893 & -0.124395 & 0.0104613 & -0.021229 & 0.0309471 & -0.0204832 & $\\dots$ \\\\\n",
       "\t2 & 0.0401683 & -0.134781 & 0.0104613 & -0.0194181 & 0.0309471 & -0.0204832 & $\\dots$ \\\\\n",
       "\t3 & -0.017679 & -0.167909 & 0.0104613 & -0.0220374 & 0.0309471 & -0.0204832 & $\\dots$ \\\\\n",
       "\t4 & -0.00963344 & -0.22925 & 0.0104613 & -0.0194181 & 0.0309471 & -0.0204832 & $\\dots$ \\\\\n",
       "\t5 & -0.0267151 & -0.176635 & 0.00324793 & -0.0208037 & 0.0309471 & -0.0204832 & $\\dots$ \\\\\n",
       "\t6 & -0.151487 & -0.189069 & 0.0104613 & 0.016953 & 0.0309471 & -0.0204832 & $\\dots$ \\\\\n",
       "\t7 & -0.166729 & -0.117739 & 0.0104613 & 0.0245505 & 0.0309471 & -0.0204832 & $\\dots$ \\\\\n",
       "\t8 & -0.0996453 & -0.0833094 & 0.00448964 & 0.021457 & 0.0309471 & -0.0204832 & $\\dots$ \\\\\n",
       "\t9 & 0.151557 & 0.319282 & -0.0448348 & -0.0366629 & 0.0309471 & -0.0204832 & $\\dots$ \\\\\n",
       "\t10 & 0.0476034 & -0.0144728 & -0.00233214 & 0.00765442 & 0.0309471 & -0.0204832 & $\\dots$ \\\\\n",
       "\t11 & 0.00814297 & -0.0349694 & 0.0104613 & 0.0101673 & -0.0309471 & 0.0204832 & $\\dots$ \\\\\n",
       "\t12 & -0.0811847 & 0.0441466 & 0.00848568 & 0.0169169 & -0.0309471 & 0.0204832 & $\\dots$ \\\\\n",
       "\t13 & -0.153504 & 0.393015 & -0.0484441 & 0.0230577 & -0.0309471 & 0.0204832 & $\\dots$ \\\\\n",
       "\t14 & -0.148069 & -0.0146316 & 0.00886135 & 0.0161103 & -0.0309471 & 0.0204832 & $\\dots$ \\\\\n",
       "\t15 & 0.0247091 & 0.0531618 & 0.00677168 & 0.0155368 & -0.0309471 & 0.0204832 & $\\dots$ \\\\\n",
       "\t16 & 0.235093 & 0.178299 & -0.00374318 & 0.000594213 & -0.0309471 & 0.0204832 & $\\dots$ \\\\\n",
       "\t17 & 0.294984 & 0.146047 & -0.00460173 & -0.0205562 & -0.0309471 & 0.0204832 & $\\dots$ \\\\\n",
       "\t18 & 0.0237644 & 0.0162414 & 0.00588019 & 0.00584345 & -0.0309471 & 0.0204832 & $\\dots$ \\\\\n",
       "\t19 & -0.116843 & -0.0173146 & 0.00543154 & 0.0053948 & -0.0309471 & 0.0204832 & $\\dots$ \\\\\n",
       "\t20 & -0.00542654 & 0.154285 & -0.0124411 & -0.00411101 & -0.0309471 & 0.0204832 & $\\dots$ \\\\\n",
       "\t21 & 0.106903 & -0.117615 & 0.00797198 & -0.0161775 & 0.0425486 & -0.0222253 & $\\dots$ \\\\\n",
       "\t22 & 0.0906478 & -0.0953381 & 0.00797198 & -0.0147974 & 0.0425486 & -0.0222253 & $\\dots$ \\\\\n",
       "\t23 & 0.0844482 & -0.115481 & 0.00797198 & -0.0167935 & 0.0425486 & -0.0222253 & $\\dots$ \\\\\n",
       "\t24 & 0.0297359 & -0.187202 & 0.00797198 & -0.0147974 & 0.0425486 & -0.0222253 & $\\dots$ \\\\\n",
       "\t25 & -0.0270093 & -0.187794 & 0.00247507 & -0.0158534 & 0.0425486 & -0.0222253 & $\\dots$ \\\\\n",
       "\t26 & -0.220044 & -0.148477 & 0.00797198 & 0.0129189 & 0.0425486 & -0.0222253 & $\\dots$ \\\\\n",
       "\t27 & -0.2442 & -0.0289042 & 0.00797198 & 0.0187086 & 0.0425486 & -0.0222253 & $\\dots$ \\\\\n",
       "\t28 & -0.217045 & 0.127496 & 0.00342131 & 0.0163512 & 0.0425486 & -0.0222253 & $\\dots$ \\\\\n",
       "\t29 & 0.10424 & 0.393619 & -0.0341662 & -0.0279388 & 0.0425486 & -0.0222253 & $\\dots$ \\\\\n",
       "\t30 & -0.172381 & -0.00919521 & -0.0017772 & 0.00583301 & 0.0425486 & -0.0222253 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3900×195 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m logrobr     \u001b[0m\u001b[1m logburg     \u001b[0m\u001b[1m burg_missing \u001b[0m\u001b[1m robrate_missing \u001b[0m\u001b[1m newblack   \u001b[0m\u001b[1m n\u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64     \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64      \u001b[0m\u001b[90m Float64         \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m F\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │  0.150893    -0.124395      0.0104613       -0.021229     0.0309471  - ⋯\n",
       "    2 │  0.0401683   -0.134781      0.0104613       -0.0194181    0.0309471  -\n",
       "    3 │ -0.017679    -0.167909      0.0104613       -0.0220374    0.0309471  -\n",
       "    4 │ -0.00963344  -0.22925       0.0104613       -0.0194181    0.0309471  -\n",
       "    5 │ -0.0267151   -0.176635      0.00324793      -0.0208037    0.0309471  - ⋯\n",
       "    6 │ -0.151487    -0.189069      0.0104613        0.016953     0.0309471  -\n",
       "    7 │ -0.166729    -0.117739      0.0104613        0.0245505    0.0309471  -\n",
       "    8 │ -0.0996453   -0.0833094     0.00448964       0.021457     0.0309471  -\n",
       "    9 │  0.151557     0.319282     -0.0448348       -0.0366629    0.0309471  - ⋯\n",
       "   10 │  0.0476034   -0.0144728    -0.00233214       0.00765442   0.0309471  -\n",
       "   11 │  0.00814297  -0.0349694     0.0104613        0.0101673   -0.0309471\n",
       "  ⋮   │      ⋮            ⋮            ⋮               ⋮             ⋮         ⋱\n",
       " 3891 │  0.0786474    0.13458      -0.0205879       -0.0207884    0.0531512  -\n",
       " 3892 │  0.0561803    0.134567     -0.0219353       -0.0161853    0.0531512  - ⋯\n",
       " 3893 │  0.209323     0.390146     -0.0607604       -0.0119974    0.0531512  -\n",
       " 3894 │ -0.0858534    0.15756      -0.0216791       -0.0167354    0.0531512  -\n",
       " 3895 │ -0.0983204    0.126737     -0.0231042       -0.0171265    0.0531512  -\n",
       " 3896 │  0.0182247    0.107714     -0.0302751       -0.0273171    0.0531512  - ⋯\n",
       " 3897 │  0.251402     0.151313     -0.0308606       -0.0417414    0.0531512  -\n",
       " 3898 │  0.179985     0.116497     -0.0237122       -0.0237372    0.0531512  -\n",
       " 3899 │ -1.3754      -3.02227       0.530429         0.530404     0.0531512  -\n",
       " 3900 │  0.336788     0.171876     -0.036207        -0.030526     0.0531512  - ⋯\n",
       "\u001b[36m                                               190 columns and 3879 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: Cannot assign to non-existent column: 1",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Cannot assign to non-existent column: 1",
      "",
      "Stacktrace:",
      " [1] insert_single_column!(df::DataFrame, v::Vector{Float64}, col_ind::Int64)",
      "   @ DataFrames C:\\Users\\PC\\.julia\\packages\\DataFrames\\3mEXm\\src\\dataframe\\dataframe.jl:512",
      " [2] setindex!(df::DataFrame, v::Vector{Float64}, #unused#::typeof(!), col_ind::Int64)",
      "   @ DataFrames C:\\Users\\PC\\.julia\\packages\\DataFrames\\3mEXm\\src\\dataframe\\dataframe.jl:541",
      " [3] top-level scope",
      "   @ .\\In[54]:11",
      " [4] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [5] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1116"
     ]
    }
   ],
   "source": [
    "mean_1 = mean.(eachcol(z))\n",
    "\n",
    "\n",
    "std_1 = std.(eachcol(z))\n",
    "\n",
    "\n",
    "\n",
    "for i in 1:size(z)[2]\n",
    "    p = (z[:, i] .- mean_1[i]) / std_1[i]\n",
    "    #colname = names(Z)[i]\n",
    "    df[!,i] = p\n",
    "end\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: Cannot assign to non-existent column: 1",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Cannot assign to non-existent column: 1",
      "",
      "Stacktrace:",
      " [1] insert_single_column!(df::DataFrame, v::Vector{Float64}, col_ind::Int64)",
      "   @ DataFrames C:\\Users\\PC\\.julia\\packages\\DataFrames\\3mEXm\\src\\dataframe\\dataframe.jl:512",
      " [2] setindex!",
      "   @ C:\\Users\\PC\\.julia\\packages\\DataFrames\\3mEXm\\src\\dataframe\\dataframe.jl:541 [inlined]",
      " [3] setindex!(df::DataFrame, v::Vector{Float64}, row_inds::Colon, col_ind::Int64)",
      "   @ DataFrames C:\\Users\\PC\\.julia\\packages\\DataFrames\\3mEXm\\src\\dataframe\\dataframe.jl:592",
      " [4] top-level scope",
      "   @ In[67]:1",
      " [5] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [6] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1116"
     ]
    }
   ],
   "source": [
    "df[:,1] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3900-element Vector{Float64}:\n",
       "  0.19297177786972372\n",
       "  0.051369841595354765\n",
       " -0.02260902583397552\n",
       " -0.012319878683044443\n",
       " -0.034165055650964275\n",
       " -0.1937313645019607\n",
       " -0.21322361685221175\n",
       " -0.12743291758859554\n",
       "  0.19382086474044877\n",
       "  0.06087839527047379\n",
       "  0.010413768831547246\n",
       " -0.10382424886614387\n",
       " -0.19631106003544865\n",
       "  ⋮\n",
       " -0.1519666509001525\n",
       " -0.028157516507789738\n",
       "  0.10057946371092834\n",
       "  0.07184702189210973\n",
       "  0.267696062135722\n",
       " -0.1097948884357846\n",
       " -0.1257385988841877\n",
       "  0.02330696441580686\n",
       "  0.3215097989527482\n",
       "  0.23017669648906897\n",
       " -1.7589560388446375\n",
       "  0.430706036235847"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = (z[:,1].-mean_1[1]) / std_1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195×3 Matrix{Any}:\n",
       " \"logrobr\"          \"logrobr\"          -2.84804e-15\n",
       " \"logburg\"          \"logburg\"           8.66521e-15\n",
       " \"burg_missing\"     \"burg_missing\"     -1.38787e-17\n",
       " \"robrate_missing\"  \"robrate_missing\"  -1.22089e-17\n",
       " \"newblack\"         \"newblack\"          3.02021e-15\n",
       " \"newfhh\"           \"newfhh\"           -5.07913e-16\n",
       " \"newmove\"          \"newmove\"           4.74788e-15\n",
       " \"newdens\"          \"newdens\"          -8.50898e-15\n",
       " \"newmal\"           \"newmal\"           -1.01486e-17\n",
       " \"AGE010D\"          \"AGE010D\"          -2.37094e-14\n",
       " \"AGE050D\"          \"AGE050D\"           8.20774e-15\n",
       " \"AGE110D\"          \"AGE110D\"           2.68134e-14\n",
       " \"AGE170D\"          \"AGE170D\"           1.65919e-14\n",
       " ⋮                                     \n",
       " \"PVY020D\"          \"PVY020D\"          -2.85392e-14\n",
       " \"PVY120D\"          \"PVY120D\"          -3.9999e-14\n",
       " \"PVY210D\"          \"PVY210D\"          -2.53837e-15\n",
       " \"PVY310D\"          \"PVY310D\"           5.4832e-14\n",
       " \"PVY420D\"          \"PVY420D\"          -4.56684e-14\n",
       " \"PVY520D\"          \"PVY520D\"           2.98352e-14\n",
       " \"SPR030D\"          \"SPR030D\"          -9.37837e-15\n",
       " \"SPR130D\"          \"SPR130D\"          -1.04047e-14\n",
       " \"SPR230D\"          \"SPR230D\"           1.05672e-14\n",
       " \"SPR330D\"          \"SPR330D\"           5.74424e-15\n",
       " \"SPR440D\"          \"SPR440D\"          -9.52036e-15\n",
       " \"VST020D\"          \"VST020D\"           3.76667e-15"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[names(Z) mean_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DML2_for_NN (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function DML2_for_NN(z , d , y, nfold, clu, num_epochs)\n",
    "    \n",
    "    # Num ob observations\n",
    "    nobser = size(z,1)\n",
    "    \n",
    "    # Define folds indices \n",
    "    foldid = collect(Kfold(size(z)[1], nfold))\n",
    "    \n",
    "    # Create array to save errors \n",
    "    ytil = ones(nobser)\n",
    "    dtil = ones(nobser)\n",
    "    println(\"Folds: \" )\n",
    "    \n",
    "    # loop to save results\n",
    "    for i in 1:nfold\n",
    "        ##############################################\n",
    "        ################| MODEL D |###################\n",
    "        model_y= Chain(Dense(size(z,2), 16, relu), \n",
    "        Dense(16, 16, relu),\n",
    "        Dense(16, 1))\n",
    "\n",
    "        opt = RMSProp()\n",
    "        loss_y(x, y) = Flux.Losses.mse(model_y(x), y)\n",
    "        metrics_y(x, y) = Flux.mae(model_y(x), y)\n",
    "        ps_y = Flux.params(model_y)\n",
    "\n",
    "        ##############################################\n",
    "        ################| MODEL Y |###################\n",
    "        model_d= Chain(Dense(size(z,2), 16, relu), \n",
    "        Dense(16, 16, relu),\n",
    "        Dense(16, 1))\n",
    "\n",
    "        opt = RMSProp()\n",
    "        loss_d(x, y) = Flux.Losses.mse(model_d(x), y)\n",
    "        metrics_d(x, y) = Flux.mae(model_d(x), y)\n",
    "        ps_d = Flux.params(model_d)\n",
    "\n",
    "        data_d = DataLoader((z[foldid[i],:]', d[foldid[i]]'))\n",
    "        data_y = DataLoader((z[foldid[i],:]', y[foldid[i]]'))\n",
    "\n",
    "    # Lasso regression, excluding folds selected \n",
    "    for epoch in 1:num_epochs\n",
    "        time = @elapsed Flux.train!(loss_y, ps_y, data_y, opt)\n",
    "    end\n",
    "\n",
    "    for epoch in 1:num_epochs\n",
    "        time = @elapsed Flux.train!(loss_d, ps_d, data_d, opt)\n",
    "    end\n",
    "\n",
    "    # Predict estimates using the \n",
    "    yhat = model_y(z[Not(foldid[i]),:]')';\n",
    "    ###############################################################################\n",
    "    dhat = model_d(z[Not(foldid[i]),:]')';\n",
    "    \n",
    "        \n",
    "    # Save errors \n",
    "    dtil[Not(foldid[i])] = (d[Not(foldid[i])] - dhat)\n",
    "    ytil[Not(foldid[i])] = (y[Not(foldid[i])] - yhat)\n",
    "\n",
    "    println(i)\n",
    "    end\n",
    "    \n",
    "    # Create dataframe \n",
    "    data = DataFrame(ytil = ytil, dtil = dtil, clu=clu)\n",
    "    \n",
    "    # OLS clustering at the County level\n",
    "    rfit = reg(data, @formula(ytil ~ dtil +fe(clu)))\n",
    "    coef_est = coef(rfit)[1]\n",
    "    se = FixedEffectModels.coeftable(rfit).cols[2]\n",
    "\n",
    "    println(\" coef (se) = \", coef_est ,\"(\",se,\")\")\n",
    "    \n",
    "    #return rfit, data;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating the effect with DLM for neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treatment variable\n",
    "D = rdata[!,d]\n",
    "\n",
    "# Outcome variable\n",
    "\n",
    "Y = rdata[!,y];\n",
    "\n",
    "# Construct matrix Z\n",
    "Z = rdata[!, varlis[3:end]];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>logghomr</th><th>logfssl</th><th>CountyCode</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Int64</th></tr></thead><tbody><p>6 rows × 3 columns</p><tr><th>1</th><td>-0.134778</td><td>0.0961271</td><td>1073</td></tr><tr><th>2</th><td>-0.239622</td><td>0.0808094</td><td>1073</td></tr><tr><th>3</th><td>-0.0786772</td><td>0.0573399</td><td>1073</td></tr><tr><th>4</th><td>-0.331465</td><td>0.0816945</td><td>1073</td></tr><tr><th>5</th><td>-0.31664</td><td>0.0253655</td><td>1073</td></tr><tr><th>6</th><td>0.105132</td><td>-0.00677726</td><td>1073</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& logghomr & logfssl & CountyCode\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & -0.134778 & 0.0961271 & 1073 \\\\\n",
       "\t2 & -0.239622 & 0.0808094 & 1073 \\\\\n",
       "\t3 & -0.0786772 & 0.0573399 & 1073 \\\\\n",
       "\t4 & -0.331465 & 0.0816945 & 1073 \\\\\n",
       "\t5 & -0.31664 & 0.0253655 & 1073 \\\\\n",
       "\t6 & 0.105132 & -0.00677726 & 1073 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m6×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m logghomr   \u001b[0m\u001b[1m logfssl     \u001b[0m\u001b[1m CountyCode \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64    \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Int64      \u001b[0m\n",
       "─────┼─────────────────────────────────────\n",
       "   1 │ -0.134778    0.0961271         1073\n",
       "   2 │ -0.239622    0.0808094         1073\n",
       "   3 │ -0.0786772   0.0573399         1073\n",
       "   4 │ -0.331465    0.0816945         1073\n",
       "   5 │ -0.31664     0.0253655         1073\n",
       "   6 │  0.105132   -0.00677726        1073"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create main variables\n",
    "z = Matrix(Z);\n",
    "d = D[!,1];\n",
    "y = Y[!,1];\n",
    "clu = rdata[!, :CountyCode];\n",
    "first(DataFrame(logghomr = y,logfssl = d,CountyCode = clu ),6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folds: \n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      " coef (se) = 0.08016811689720804([0.059424888983297536])\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "DML2_for_NN(z,d,y,10,clu,100)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c469c999aae2bf6d578d6881606ced546d1546d312a4811937df5b24665ee8bc"
  },
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
